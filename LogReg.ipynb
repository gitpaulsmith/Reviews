{
 "metadata": {
  "name": "",
  "signature": "sha256:c8bcc472db8b9dd9c5e0fdca70e328020f51eef2e95691ec49e9c7558d8ac6c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import required packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = 'scrubbed_foods.csv'\n",
      "f = open(fn,'rb')\n",
      "df = pd.io.parsers.read_table(f, '\\t!\\t',engine='python')\n",
      "f.close()\n",
      "df.drop_duplicates('text',inplace=True)\n",
      "\n",
      "#Shuffle the data\n",
      "#df = df.reindex(np.random.permutation(df.index))\n",
      "\n",
      "df_1star = pd.DataFrame(df[df['score']==1],columns=['score','text'])\n",
      "df_2star = pd.DataFrame(df[df['score']==2],columns=['score','text'])\n",
      "df_3star = pd.DataFrame(df[df['score']==3],columns=['score','text'])\n",
      "df_4star = pd.DataFrame(df[df['score']==4],columns=['score','text'])\n",
      "df_5star = pd.DataFrame(df[df['score']==5],columns=['score','text'])\n",
      "\n",
      "min_star_length = min(len(df_1star), len(df_2star), len(df_3star), len(df_4star), len(df_5star))\n",
      "\n",
      "#Train and test on data with stars equally distributed across classes\n",
      "#Percentage of data to use in training and cross-validation:\n",
      "frac = 0.7\n",
      "idx1 = int(min_star_length*frac)\n",
      "idx2 = min_star_length\n",
      "\n",
      "training_pieces = [df_1star[:idx1],df_2star[:idx1], df_3star[:idx1], df_4star[:idx1], df_5star[:idx1]]\n",
      "leftovers = [df_1star[idx1:idx2],df_2star[idx1:idx2], df_3star[idx1:idx2], df_4star[idx1:idx2], df_5star[idx1:idx2]]\n",
      "del df_1star, df_2star, df_3star, df_4star, df_5star\n",
      "\n",
      "df_train = pd.concat(training_pieces)\n",
      "df_test = pd.concat(leftovers)\n",
      "del training_pieces\n",
      "del leftovers\n",
      "\n",
      "def decodeArray(text):\n",
      "    try:\n",
      "        return text.decode('utf-8','replace')\n",
      "    except:\n",
      "        return 0\n",
      "\n",
      "X_train = df_train['text'].apply(decodeArray)\n",
      "y_train = df_train['score']\n",
      "X_test = df_test['text'].apply(decodeArray)\n",
      "y_test = df_test['score']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Confusion Matrix normalizer and plotter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeCM_plot(y_test, y_pred):\n",
      "    cm = confusion_matrix(y_test, y_pred)\n",
      "    cm=cm / cm.astype(np.float).sum(axis=1)\n",
      "    print cm\n",
      "    plt.matshow(cm)\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.colorbar()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.savefig('LogReg.png')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#vectorizer = CountVectorizer(decode_error='replace', strip_accents='ascii',stop_words=None,max_features=2000,ngram_range=(1,2))\n",
      "#vectorizer = TfidfVectorizer(decode_error='replace', strip_accents='ascii',stop_words=None,max_features=5000,use_idf=True,ngram_range=(1,2))\n",
      "vectorizer=TfidfVectorizer(analyzer='word', binary=True, decode_error='replace',\n",
      "         max_df=1.0, max_features=2000, min_df=2,\n",
      "         ngram_range=(1, 2), norm=u'l2', smooth_idf=True,\n",
      "         stop_words=None, sublinear_tf=False,\n",
      "         use_idf=True)\n",
      "vec = vectorizer.fit_transform(df_train['text'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "X = vec\n",
      "Y = df_train['score']\n",
      "\n",
      "logreg = linear_model.LogisticRegression(C=1)\n",
      "\n",
      "# we create an instance of Neighbours Classifier and fit the data.\n",
      "logreg.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectest = vectorizer.transform(X_test)\n",
      "y_pred = logreg.predict(vectest)\n",
      "print 'Score: ', logreg.score(vectest, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "makeCM_plot(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}