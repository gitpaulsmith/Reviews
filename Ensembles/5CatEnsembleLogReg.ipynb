{
 "metadata": {
  "name": "",
  "signature": "sha256:622c0357607fd52110f5252a9e08f480abe98491a8a7bbd341ef2cc70cb200c4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Import required packages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn import linear_model\n",
      "from sklearn import svm\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('scrubbed_foods.csv','\\t!\\t')\n",
      "df.drop_duplicates('text',inplace=True)\n",
      "\n",
      "#Shuffle the data\n",
      "#df = df.reindex(np.random.permutation(df.index))\n",
      "\n",
      "df_1star = pd.DataFrame(df[df['score']==1],columns=['score','text'])\n",
      "df_2star = pd.DataFrame(df[df['score']==2],columns=['score','text'])\n",
      "df_3star = pd.DataFrame(df[df['score']==3],columns=['score','text'])\n",
      "df_4star = pd.DataFrame(df[df['score']==4],columns=['score','text'])\n",
      "df_5star = pd.DataFrame(df[df['score']==5],columns=['score','text'])\n",
      "\n",
      "min_star_length = min(len(df_1star), len(df_2star), len(df_3star), len(df_4star), len(df_5star))\n",
      "\n",
      "#Train and test on data with stars equally distributed across classes\n",
      "#Percentage of data to use in training and cross-validation:\n",
      "frac = 0.7\n",
      "idx1 = int(min_star_length*frac*frac)\n",
      "idx2 = int(min_star_length*frac)\n",
      "idx3 = min_star_length\n",
      "\n",
      "training_data = [df_1star[:idx1],df_2star[:idx1], df_3star[:idx1], df_4star[:idx1], df_5star[:idx1]]\n",
      "training_data2 = [df_1star[idx1:idx2],df_2star[idx1:idx2], df_3star[idx1:idx2], df_4star[idx1:idx2], df_5star[idx1:idx2]]\n",
      "testing_data = [df_1star[idx2:idx3],df_2star[idx2:idx3], df_3star[idx2:idx3], df_4star[idx2:idx3], df_5star[idx2:idx3]]\n",
      "del df_1star, df_2star, df_3star, df_4star, df_5star\n",
      "\n",
      "df_train = pd.concat(training_data)\n",
      "df_train2 = pd.concat(training_data2)\n",
      "df_test = pd.concat(testing_data)\n",
      "del training_data, training_data2, testing_data\n",
      "\n",
      "def decodeArray(text):\n",
      "    try:\n",
      "        return text.decode('utf-8','replace')\n",
      "    except:\n",
      "        return 0\n",
      "\n",
      "X_train = df_train['text'].apply(decodeArray)\n",
      "y_train = df_train['score']\n",
      "X_train2 = df_train2['text'].apply(decodeArray)\n",
      "y_train2 = df_train2['score']\n",
      "X_test = df_test['text'].apply(decodeArray)\n",
      "y_test = df_test['score']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Confusion Matrix normalizer and plotter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeCM_plot(y_test, y_pred):\n",
      "    cm = confusion_matrix(y_test, y_pred)\n",
      "    cm=cm / cm.astype(np.float).sum(axis=1)\n",
      "    print cm\n",
      "    plt.matshow(cm)\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.colorbar()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM_Vectorizer=TfidfVectorizer(analyzer='word', binary=True, charset=None,\n",
      "        charset_error=None, decode_error=u'strict',\n",
      "        encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "\n",
      "SVM_clf=svm.LinearSVC(loss='l2', penalty='l1', dual=False)\n",
      "SVM_pipeline=Pipeline([('vect', SVM_Vectorizer),('clf', SVM_clf)])\n",
      "SVM_pipeline.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
        "        ngram_range=(1, 2), norm=...ling=1, loss='l2', multi_class='ovr', penalty='l1',\n",
        "     random_state=None, tol=0.0001, verbose=0))])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SVM_pipeline.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "0.85381368410719549"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_SVMpred = SVM_pipeline.predict(X_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_SVMtest = SVM_pipeline.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Naive Bayes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The parameters for the best NB classifier (cross-validated elsewhere) are as follows:\n",
      "NB_Vectorizer=TfidfVectorizer(analyzer='word', binary=False, charset=None,charset_error=None,decode_error='strict',\n",
      "                       encoding='utf-8',lowercase=True,\n",
      "                       max_df=1.0,max_features=None,min_df=1,ngram_range=(1, 3),norm='l2',\n",
      "                       preprocessor=None,smooth_idf=False,stop_words=None,strip_accents=None,\n",
      "                       sublinear_tf=False,token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',tokenizer=None,use_idf=False,vocabulary=None)\n",
      "#Classsifier:\n",
      "NB_clf=MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "NB_pipeline=Pipeline([('vect', NB_Vectorizer),('clf', NB_clf)])\n",
      "NB_pipeline.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error='strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding='utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "        ngram_range=(1, 3), norm='l...lse,\n",
        "        vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NB_pipeline.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.98798468636497494"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_NBpred = NB_pipeline.predict(X_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_NBtest = NB_pipeline.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load sentiment files for Bag of Words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the positive and negative word files from http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
      "# Direct link http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar\n",
      "\n",
      "posfn = './opinion-lexicon-English/positive-words.txt'\n",
      "negfn = './opinion-lexicon-English/negative-words.txt'\n",
      "\n",
      "poswords = pd.read_table(posfn,skiprows=35,header=None,squeeze=True)\n",
      "\n",
      "poswords.dropna(how='all',inplace=True)\n",
      "poswords.reset_index(drop=True,inplace=True)\n",
      "\n",
      "negwords = pd.read_csv(negfn, skiprows=35, header=None, squeeze=True)\n",
      "negwords.dropna(how='all',inplace=True)\n",
      "negwords.reset_index(drop=True,inplace=True)\n",
      "\n",
      "# Find columns in vectorized data that correspond to positive or negative words\n",
      "\n",
      "vectorizer = CountVectorizer(decode_error='replace', strip_accents='ascii',stop_words='english')\n",
      "Xmat_train = vectorizer.fit_transform(df_train['text'])\n",
      "Xmat_train2 = vectorizer.fit_transform(df_train2['text'])\n",
      "Xmat_test = vectorizer.fit_transform(df_test['text'])\n",
      "vocab = vectorizer.vocabulary_\n",
      "\n",
      "poscol, negcol = [], []\n",
      "for word in poswords:\n",
      "    if word in vocab:\n",
      "        poscol.append(vocab[word])\n",
      "for word in negwords:\n",
      "    if word in vocab:\n",
      "        negcol.append(vocab[word])\n",
      "\n",
      "vectorizerpos = CountVectorizer(decode_error='replace', strip_accents='ascii',stop_words='english', vocabulary=poswords)\n",
      "Xpos_train = vectorizerpos.fit_transform(df_train['text'])\n",
      "Xpos_train2 = vectorizerpos.fit_transform(df_train2['text'])\n",
      "Xpos_test = vectorizerpos.fit_transform(df_test['text'])\n",
      "\n",
      "vectorizerneg = CountVectorizer(decode_error='replace', strip_accents='ascii',stop_words='english', vocabulary=negwords)\n",
      "Xneg_train = vectorizerneg.fit_transform(df_train['text'])\n",
      "Xneg_train2 = vectorizerneg.fit_transform(df_train2['text'])\n",
      "Xneg_test = vectorizerneg.fit_transform(df_test['text'])\n",
      "\n",
      "from __future__ import division\n",
      "poscnt = np.array(Xpos_train.sum(1)).flatten()\n",
      "negcnt = np.array(Xneg_train.sum(1)).flatten()\n",
      "fullcnt = np.array(Xmat_train.sum(1)).flatten()\n",
      "score = (poscnt - negcnt) / fullcnt\n",
      "df_train['text_score'] = 10*score\n",
      "\n",
      "def safelen(x):\n",
      "    try:\n",
      "        return len(x) / 100 #feature scaling\n",
      "    except:\n",
      "        return 0\n",
      "df_train['textlen'] = df_train['text'].apply(safelen)\n",
      "\n",
      "poscnt = np.array(Xpos_train2.sum(1)).flatten()\n",
      "negcnt = np.array(Xneg_train2.sum(1)).flatten()\n",
      "fullcnt = np.array(Xmat_train2.sum(1)).flatten()\n",
      "score = (poscnt - negcnt) / fullcnt\n",
      "\n",
      "df_train2['text_score'] = 10*score\n",
      "df_train2['textlen'] = df_train2['text'].apply(safelen)\n",
      "\n",
      "\n",
      "poscnt = np.array(Xpos_test.sum(1)).flatten()\n",
      "negcnt = np.array(Xneg_test.sum(1)).flatten()\n",
      "fullcnt = np.array(Xmat_test.sum(1)).flatten()\n",
      "score = (poscnt - negcnt) / fullcnt\n",
      "\n",
      "df_test['text_score'] = 10*score\n",
      "df_test['textlen'] = df_test['text'].apply(safelen)\n",
      "\n",
      "#df.dropna(inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Xtra_train = df_train[['text_score', 'textlen']].as_matrix()\n",
      "Xtxtsc_train = df_train[['text_score']].as_matrix()\n",
      "Xtxtlen_train = df_train[['textlen']].as_matrix()\n",
      "Xtxtsc_train2 = df_train2[['text_score']].as_matrix()\n",
      "Xtxtlen_train2 = df_train2[['textlen']].as_matrix()\n",
      "Xtra_test = df_test[['text_score', 'textlen']].as_matrix()\n",
      "\n",
      "Xtxtsc_train = Xtxtsc_train.flatten()\n",
      "Xtxtlen_train = Xtxtlen_train.flatten()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A=np.vstack((Xtxtsc_train2, y_SVMpred, y_NBpred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-112-0f76dd10675b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtxtsc_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_SVMpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_NBpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(Xtxtsc_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "21830"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(y_SVMpred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "21830"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg = linear_model.LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ens_train2 = np.vstack((y_SVMpred, y_NBpred)).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.fit(Ens_train2, y_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.score(Ens_train2, y_train2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "0.46454420522217132"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ens_test = np.vstack((y_SVMtest, y_NBtest)).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_Enspred = logreg.predict(Ens_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "makeCM_plot(y_test, y_Enspred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.81516512  0.0803142   0.05995511  0.02436678  0.02019878]\n",
        " [ 0.53622956  0.1769798   0.18002565  0.0575505   0.04921449]\n",
        " [ 0.22042321  0.16142995  0.34578391  0.12792562  0.14443732]\n",
        " [ 0.05787111  0.05706957  0.18146842  0.15421609  0.5493748 ]\n",
        " [ 0.03350433  0.01763386  0.0472908   0.06091696  0.84065406]]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAADvCAYAAAAZ4tq4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsleoY3k+UIwiIiIiIiIiIiIiItKR/h/A/u0u69DAhwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x122e37e90>"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
