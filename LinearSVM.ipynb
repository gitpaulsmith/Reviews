{
 "metadata": {
  "name": "",
  "signature": "sha256:7fb768d190478129573955d2a2d96dbdc657938f6a6babd531f2035008ed743b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab as pl\n",
      "import scipy\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " df = pd.read_csv('scrubbed_foods.csv','\\t!\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/pandas/io/parsers.py:615: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
        "  ParserWarning)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we will drop duplicate reviews. Applying shape both before and after, we can tell how many duplicates are eliminated."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(568447, 8)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.drop_duplicates('text')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(393573, 8)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we partition the reviews into \"good\" reviews and \"bad\" reviews. Here we adopt the convention that 4- and 5-star reviews are good and 1- and 2-star reviews are bad. For the time being we ignore 3-star reviews."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfhi = df[df['score']>3]\n",
      "dflo = df[df['score']<3]\n",
      "\n",
      "dfconcat = pd.concat([dfhi, dflo])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We take dfconcat, which contains all reviews except those earning 3 stars, and randomly split it into training and test data. Here we put 60% of the data into the training set and reserve 40% for the test set. Note that we independently draw from dfconcat as a whole and not from dfhi or dflo separately; as a result, the precise good/bad review split in the training data can vary from run to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.random.seed(0)\n",
      "dfconcat = dfconcat.reindex(np.random.permutation(dfconcat.index))\n",
      "n_sample = len(dfconcat)\n",
      "m_train = int(0.6*n_sample)\n",
      "dftrain = dfconcat.head(m_train)\n",
      "dfextremestest = dfconcat.tail(n_sample-m_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we create a count_vect object that we will use to create a document-term matrix. In order to avoid load errors, we specify the decode_error as 'replace' rather than the default 'strict'. In an effort to generate a cleaner set of terms, we also set the strip_accents option to 'ascii'.\n",
      "\n",
      "The fit_transform method creates the document-term matrix in (sparse) coo format. We convert this to csr to achieve performance gains in the svm step.\n",
      "\n",
      "The y_train vector is a numpy array and is not expected to be sparse."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_vect = CountVectorizer(decode_error='replace', strip_accents='ascii')\n",
      "X_train = count_vect.fit_transform(dftrain['text'])\n",
      "X_train = X_train.tocsr()\n",
      "ds = dftrain['score']>3\n",
      "y_train = ds.astype(np.int).values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we construct the support vector machine. Because of the (large) size of the data, and to establish a decent baseline, we opt for a linear model. We use the 'l1' penalty so as to obtain sparse coefficient vectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.LinearSVC(loss='l2', penalty='l1', dual=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The training step, which is next, takes about 1.5 minutes to run on my machine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l1',\n",
        "     random_state=None, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature names (words in the reviews) are only extracted from the training data. We creat an iterable object of these to use in converting the test data into a document-term matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = count_vect.get_feature_names()\n",
      "count_vect_test = CountVectorizer(decode_error='replace', strip_accents='ascii', vocabulary = features)\n",
      "X_extremestest = count_vect.transform(dfextremestest['text'])\n",
      "dstest = dfextremestest['score']>3\n",
      "y_extremestest = dstest.astype(np.int).values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we check to see how the classifier performs on the training data and test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.97399354992395504"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X_extremestest, y_extremestest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.92158897256885275"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualize the peformance with the following confusion matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_predict = clf.predict(X_extremestest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cm = confusion_matrix(y_extremestest, y_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.matshow(cm)\n",
      "plt.title('Confusion matrix')\n",
      "plt.colorbar()\n",
      "plt.ylabel('True label')\n",
      "plt.xlabel('Predicted label')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below we present an alternative way to run cross-validation. Unlike the procedure used above, this procedure creates the document-term matrix using all words in the available data (i.e., including words in the test data that do not occur in the training data)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_vect = CountVectorizer(decode_error='replace', strip_accents='ascii')\n",
      "X = count_vect.fit_transform(dfconcat['text'])\n",
      "X = X.tocsr()\n",
      "ds = dfconcat['score']>3\n",
      "y = ds.astype(np.int).values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}